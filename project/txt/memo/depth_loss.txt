# 訓練コード
            # Depth loss.
            if self.L_d <= 0: # if optim_idx <= 2 and self.L_d <= 0:
                loss_depth = torch.zeros_like(loss_pos).detach() # Dummy
            # else:
            #     with torch.no_grad():
            #         use_num_max = self.dep_loss_use_num_max
            #         use_num = torch.clip(gb_mask.sum(dim=(1, 2)).min(), min=0, max=use_num_max).item()
            #         dep_loss_invdist = []
            #         dep_loss_rays_d_cam = []
            #         for baich_idx in range(current_frame_num*batch_size):
            #             valid_pix_num = gb_mask[baich_idx].sum()
            #             sampled_idx = np.random.choice(range(valid_pix_num), use_num, replace=False)
            #             sampled_dist = clopped_invdist[baich_idx][gb_mask[baich_idx]][sampled_idx]
            #             dep_loss_invdist.append(sampled_dist[None, :]) # dummy H, W
            #             sampled_rays = rays_d_cam[baich_idx][gb_mask[baich_idx]][sampled_idx]
            #             dep_loss_rays_d_cam.append(sampled_rays[None, :, :]) # dummy H, W, 3
            #         dep_loss_invdist = torch.stack(dep_loss_invdist, dim=0) # clopped_invdist # 
            #         dep_loss_rays_d_cam = torch.stack(dep_loss_rays_d_cam, dim=0) # rays_d_cam # 
                
            #     # Reshape estimations.
            #     # est_obj_pos_wrd = frame_gt_obj_pos_wrd[:, 0].clone().detach()
            #     # est_obj_scale = frame_gt_obj_scale_wrd[:, 0].clone().detach()
            #     # est_obj_axis_red_wrd = frame_gt_obj_red_wrd[:, 0].clone().detach()
            #     # est_obj_axis_green_wrd = frame_gt_obj_green_wrd[:, 0].clone().detach()
            #     # est_shape_code = gt_shape_code.clone().detach()
            #     for_dep_est_obj_pos_wrd = est_obj_pos_wrd[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 3)
            #     for_dep_est_obj_scale = est_obj_scale[:, None, :].expand(-1, current_frame_num, -1).reshape(-1)
            #     for_dep_est_obj_axis_red_wrd = est_obj_axis_red_wrd[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 3)
            #     for_dep_est_obj_axis_green_wrd = est_obj_axis_green_wrd[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 3)
            #     for_dep_est_shape_code = est_shape_code[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 256)
            #     for_dep_est_obj_axis_green_cam = torch.sum(for_dep_est_obj_axis_green_wrd.reshape(-1, 3)[..., None, :]*w2c, dim=-1)
            #     for_dep_est_obj_axis_red_cam = torch.sum(for_dep_est_obj_axis_red_wrd.reshape(-1, 3)[..., None, :]*w2c, dim=-1)

            #     # Get rays.
            #     est_o2c = axis2rotation(for_dep_est_obj_axis_green_cam, for_dep_est_obj_axis_red_cam)
            #     rays_d_obj = torch.sum(dep_loss_rays_d_cam[..., None, :]*est_o2c[..., None, None, :, :].permute(0, 1, 2, 4, 3), -1)
            #     obj_pos_cam = torch.sum((for_dep_est_obj_pos_wrd - cam_pos_wrd)[..., None, :]*w2c, dim=-1)
            #     cam_pos_obj = - torch.sum(obj_pos_cam[..., None, :]*est_o2c.permute(0, 2, 1), dim=-1) / for_dep_est_obj_scale[:, None]
            #     rays_o_obj = cam_pos_obj[:, None, None, :].expand(-1, rays_d_obj.shape[1], rays_d_obj.shape[2], -1)

            #     # Cal Loss
            #     est_invdistance_map_obj_scale, _ = self.ddf.forward_from_far(rays_o_obj, rays_d_obj, for_dep_est_shape_code)
            #     est_invdistance_map = est_invdistance_map_obj_scale / for_dep_est_obj_scale[:, None, None]
            #     loss_depth = torch.abs(dep_loss_invdist - est_invdistance_map).mean()

            #     # # Debug
            #     # gt_dist = 1 / dep_loss_invdist
            #     # gt_pc_wrd = torch.sum((gt_dist[..., None]*dep_loss_rays_d_cam)[..., None, :]*w2c.permute(0, 2, 1)[:, None, None, :, :], dim=-1) + cam_pos_wrd[:, None, None, :]
            #     # point1 = gt_pc_wrd[:5][gt_dist[:5]<2].to('cpu').detach().numpy().copy()
            #     # est_dist = 1 / est_invdistance_map
            #     # est_pc_wrd = torch.sum((est_dist[..., None]*dep_loss_rays_d_cam)[..., None, :]*w2c.permute(0, 2, 1)[:, None, None, :, :], dim=-1) + cam_pos_wrd[:, None, None, :]
            #     # point2 = est_pc_wrd[:5][est_dist[:5]<2].to('cpu').detach().numpy().copy()
            #     # import matplotlib.pyplot as plt
            #     # from mpl_toolkits.mplot3d import Axes3D
            #     # fig = plt.figure()
            #     # ax = Axes3D(fig)
            #     # ax.set_xlabel("X")_d 

            # Depth loss.
            if step_mode=='val' and optim_idx==(self.total_itr-1):
                if optim_idx <= 2 or self.L_d <= 0:
                    loss_depth = torch.zeros_like(self.mseloss(est_obj_pos_wrd, frame_gt_obj_pos_wrd[:, 0])).detach() # Dummy
                # else:
                #     use_num_max = self.dep_loss_use_num_max
                #     use_num = torch.clip(gb_mask.sum(dim=(1, 2)).min(), min=0, max=use_num_max).item()
                #     dep_loss_invdist = []
                #     dep_loss_rays_d_cam = []
                #     for baich_idx in range(current_frame_num*batch_size):
                #         valid_pix_num = gb_mask[baich_idx].sum()
                #         sampled_idx = np.random.choice(range(valid_pix_num), use_num, replace=False)
                #         sampled_dist = clopped_invdist[baich_idx][gb_mask[baich_idx]][sampled_idx]
                #         dep_loss_invdist.append(sampled_dist[None, :]) # dummy H, W
                #         sampled_rays = rays_d_cam[baich_idx][gb_mask[baich_idx]][sampled_idx]
                #         dep_loss_rays_d_cam.append(sampled_rays[None, :, :]) # dummy H, W, 3
                #     dep_loss_invdist = torch.stack(dep_loss_invdist, dim=0)
                #     dep_loss_rays_d_cam = torch.stack(dep_loss_rays_d_cam, dim=0)

                #     # Reshape estimations.
                #     for_dep_est_obj_pos_wrd = est_obj_pos_wrd[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 3)
                #     for_dep_est_obj_scale = est_obj_scale[:, None, :].expand(-1, current_frame_num, -1).reshape(-1)
                #     for_dep_est_obj_axis_red_wrd = est_obj_axis_red_wrd[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 3)
                #     for_dep_est_obj_axis_green_wrd = est_obj_axis_green_wrd[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 3)
                #     for_dep_est_shape_code = est_shape_code[:, None, :].expand(-1, current_frame_num, -1).reshape(-1, 256)
                #     for_dep_est_obj_axis_green_cam = torch.sum(for_dep_est_obj_axis_green_wrd.reshape(-1, 3)[..., None, :]*w2c, dim=-1)
                #     for_dep_est_obj_axis_red_cam = torch.sum(for_dep_est_obj_axis_red_wrd.reshape(-1, 3)[..., None, :]*w2c, dim=-1)

                #     # Get rays.
                #     est_o2c = axis2rotation(for_dep_est_obj_axis_green_cam, for_dep_est_obj_axis_red_cam)
                #     rays_d_obj = torch.sum(dep_loss_rays_d_cam[..., None, :]*est_o2c[..., None, None, :, :].permute(0, 1, 2, 4, 3), -1)
                #     obj_pos_cam = torch.sum((for_dep_est_obj_pos_wrd - cam_pos_wrd)[..., None, :]*w2c, dim=-1)
                #     cam_pos_obj = - torch.sum(obj_pos_cam[..., None, :]*est_o2c.permute(0, 2, 1), dim=-1) / for_dep_est_obj_scale[:, None]
                #     rays_o_obj = cam_pos_obj[:, None, None, :].expand(-1, -1, use_num, -1)

                #     # Cal Loss
                #     est_invdistance_map_obj_scale, _ = self.ddf.forward_from_far(rays_o_obj, rays_d_obj, for_dep_est_shape_code)
                #     est_invdistance_map = est_invdistance_map_obj_scale / for_dep_est_obj_scale[:, None, None]
                #     loss_depth = torch.abs(dep_loss_invdist - est_invdistance_map).mean()
                