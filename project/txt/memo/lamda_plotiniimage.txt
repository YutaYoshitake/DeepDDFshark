
                    ##################################################
                    ##################################################
                    ##################################################
                    H = clopped_H
                    obj_pos_wrd = est_obj_pos_wrd
                    axis_green = est_obj_axis_green_cam
                    axis_red = est_obj_axis_red_cam
                    obj_scale = est_obj_scale[:, 0]
                    input_lat_vec = est_shape_code
                    cam_pos_wrd = cam_pos_wrd
                    rays_d_cam = sampled_rays_d_cam
                    w2c = w2c.detach()
                    obj_pos_cam = 'not_given'
                    ddf = self.ddf
                    with_invdistance_map = True

                    # Get rotation matrix.
                    axis_blue = torch.cross(axis_red, axis_green, dim=-1)
                    axis_blue = F.normalize(axis_blue, dim=-1)
                    orthogonal_axis_red = torch.cross(axis_green, axis_blue, dim=-1)
                    o2c = torch.stack([orthogonal_axis_red, axis_green, axis_blue], dim=-1)

                    # Get rays direction.
                    rays_d_obj = torch.sum(rays_d_cam[..., None, :]*o2c[..., None, None, :, :].permute(0, 1, 2, 4, 3), -1)

                    # Get rays origin.
                    if obj_pos_cam == 'not_given':
                        obj_pos_cam = torch.sum((obj_pos_wrd - cam_pos_wrd)[..., None, :]*w2c, dim=-1)
                    cam_pos_obj = - torch.sum(obj_pos_cam[..., None, :]*o2c.permute(0, 2, 1), dim=-1) / obj_scale[:, None]
                    rays_o_obj = cam_pos_obj[:, None, None, :].expand(-1, H, H, -1)

                    # Get rays inputs.
                    rays_d = rays_d_obj
                    rays_o = rays_o_obj

                    # Estimating.
                    # est_invdistance_map_obj_scale, _ = ddf.forward_from_far(rays_o, rays_d, input_lat_vec)
                    ##################################################
                    ##################################################
                    ##################################################
                    origin = self.ddf.origin.to(rays_o)
                    radius = self.ddf.radius
                    D = torch.sum(rays_d * (rays_o - origin), dim=-1)**2 - (torch.sum((rays_o - origin)**2, dim=-1) - radius**2)
                    negative_D_mask = D < 1e-12
                    d_dot_o = torch.sum(rays_d * (rays_o - origin), dim=-1)
                    D[negative_D_mask] = 1e-12
                    sqrt_D = torch.sqrt(D)
                    t_minus = - d_dot_o - sqrt_D
                    t_plus = - d_dot_o + sqrt_D
                    t_mask = torch.abs(t_plus) > torch.abs(t_minus)
                    t = t_plus
                    t[t_mask] = t_minus[t_mask]
                    intersect_rays_o = rays_o + t_plus[..., None] * rays_d
                    intersect_rays_o[t_mask] = (rays_o + t_minus[..., None] * rays_d)[t_mask]
                    est_invdepth_rawmap = self.ddf.forward(intersect_rays_o, rays_d, input_lat_vec)
                    est_invdistance_map_obj_scale = est_invdepth_rawmap / (1. + est_invdepth_rawmap * t.to(est_invdepth_rawmap))
                    est_invdistance_map_obj_scale[negative_D_mask] = 0
                    est_invdistance_map_for_deptherr = est_invdistance_map_obj_scale / obj_scale[:, None, None]
                    ##################################################
                    ##################################################
                    ##################################################







                with torch.no_grad():
                    rays_d_cam = self.rays_d_cam.expand(2, -1, -1, -1).to(frame_camera_rot.device)
                    est_mask, est_distance_map = render_distance_map_from_axis(
                                                    H = self.ddf_H, 
                                                    cam_pos_wrd = cam_pos_wrd[:2], 
                                                    obj_pos_wrd = est_obj_pos_wrd[:2], 
                                                    axis_green = est_obj_axis_green_cam[:2], 
                                                    axis_red = est_obj_axis_red_cam[:2], 
                                                    obj_scale = est_obj_scale[:2][:, 0], 
                                                    input_lat_vec = gt_shape_code[:2], 
                                                    rays_d_cam = rays_d_cam,  
                                                    w2c = w2c[:2].detach(), 
                                                    ddf = self.ddf, 
                                                    with_invdistance_map = False, 
                                                    )
                    clopped_est_mask, clopped_est_distance_map, _ = clopping_distance_map(
                                                                        est_mask, est_distance_map, self.image_coord, self.input_H, self.input_W, self.ddf_H, bbox_list[:2]
                                                                        )

                    # Plotを作成
                    gt_obj_pos_cam = torch.sum((gt_obj_pos_wrd-cam_pos_wrd)[..., None, :]*w2c, dim=-1)
                    fig = pylab.figure(figsize=(20, 8))
                    # BBoxをピクセル座標へ
                    bbox_list = 128 * (bbox_list.to('cpu').detach().numpy().copy() + 1)
                    bbox_center = bbox_list.mean(1)
                    obj_pos_cam = 128 * (gt_obj_pos_cam / im2cam_scale[:, None] + 1).to('cpu').detach().numpy().copy()
                    obj_pos_cam_ = 128 * (est_obj_pos_cam / im2cam_scale[:, None] + 1).to('cpu').detach().numpy().copy()
                    # bbox_center = 128 * (bbox_center.to('cpu').detach().numpy().copy() + 1)
                    bbox = np.concatenate([bbox_list, bbox_center[:, None, :], obj_pos_cam[:, None, :2], obj_pos_cam_[:, None, :2]], axis=1)
                    # bbox = np.concatenate([bbox_list, obj_pos_cam[:, None, :2]], axis=1)
                    bbox_1 = bbox[0]
                    bbox_2 = bbox[1]
                    # 元画像
                    ax_1 = fig.add_subplot(2, 5, 1)
                    ax_1.scatter(bbox_1[:, 0], bbox_1[:, 1], c='red', s=20)
                    ax_1.imshow(raw_distance_map[0].to('cpu').detach().numpy().copy())
                    ax_2 = fig.add_subplot(2, 5, 6)
                    ax_2.scatter(bbox_2[:, 0], bbox_2[:, 1], c='red', s=20)
                    ax_2.imshow(raw_distance_map[1].to('cpu').detach().numpy().copy())
                    # クロップした観測画像
                    ax_3 = fig.add_subplot(2, 5, 2)
                    ax_3.imshow(clopped_distance_map[0].to('cpu').detach().numpy().copy())
                    ax_4 = fig.add_subplot(2, 5, 7)
                    ax_4.imshow(clopped_distance_map[1].to('cpu').detach().numpy().copy())
                    # 元画像の予測
                    ax_5 = fig.add_subplot(2, 5, 3)
                    ax_5.scatter(bbox_1[:, 0], bbox_1[:, 1], c='red', s=20)
                    ax_5.imshow(est_distance_map[0].to('cpu').detach().numpy().copy())
                    ax_6 = fig.add_subplot(2, 5, 8)
                    ax_6.scatter(bbox_2[:, 0], bbox_2[:, 1], c='red', s=20)
                    ax_6.imshow(est_distance_map[1].to('cpu').detach().numpy().copy())
                    # クロップした画像の予測
                    ax_7 = fig.add_subplot(2, 5, 4)
                    ax_7.imshow(clopped_est_distance_map[0].to('cpu').detach().numpy().copy())
                    ax_8 = fig.add_subplot(2, 5, 9)
                    ax_8.imshow(clopped_est_distance_map[1].to('cpu').detach().numpy().copy())
                    # 誤差
                    clopped_error = torch.abs(clopped_distance_map[:2] - clopped_est_distance_map)
                    ax_9 = fig.add_subplot(2, 5, 5)
                    ax_9.imshow(clopped_error[0].to('cpu').detach().numpy().copy())
                    ax_10 = fig.add_subplot(2, 5, 10)
                    ax_10.imshow(clopped_error[1].to('cpu').detach().numpy().copy())
                    # 画像を保存
                    fig.savefig(f"tes.png", dpi=300)
                    # fig.savefig(f"tes.png", dpi=300)
                    pylab.close()
                    import pdb; pdb.set_trace()








                # ###################################
                # #####    Start Lamda Step     #####
                # ###################################
                # for half_lambda_idx in range(self.half_lambda_max):
                #     import pdb; pdb.set_trace()
                #     # print(f'lamda_{half_lambda_idx}')
                #     # Reshape to (batch, frame, ?)
                #     inp_est_obj_pos_wrd = est_obj_pos_wrd[:, None, :].expand(-1, opt_frame_num, -1).reshape(-1, 3)
                #     inp_est_obj_scale = est_obj_scale[:, None, :].expand(-1, opt_frame_num, -1).reshape(-1, 1)
                #     inp_est_obj_axis_green_wrd = est_obj_axis_green_wrd[:, None, :].expand(-1, opt_frame_num, -1).reshape(-1, 3)
                #     inp_est_obj_axis_red_wrd = est_obj_axis_red_wrd[:, None, :].expand(-1, opt_frame_num, -1).reshape(-1, 3)
                #     inp_est_shape_code = est_shape_code[:, None, :].expand(-1, opt_frame_num, -1).reshape(-1, self.ddf.latent_size)
                #     inp_est_obj_pos_cam = torch.sum((inp_est_obj_pos_wrd - cam_pos_wrd)[..., None, :]*w2c, dim=-1)
                #     inp_est_obj_pos_cim = torch.cat([
                #                             (inp_est_obj_pos_cam[:, :-1] / im2cam_scale[:, None] - bbox_center) / cim2im_scale[:, None], 
                #                             (inp_est_obj_pos_cam[:, -1] - avg_depth_map)[:, None]], dim=-1)
                #     inp_est_obj_scale_cim = inp_est_obj_scale / (im2cam_scale[:, None] * cim2im_scale[:, None] * 2 * math.sqrt(2))

                #     # Simulate DDF.
                #     inp_est_obj_axis_green_cam = torch.sum(inp_est_obj_axis_green_wrd[..., None, :]*w2c, -1)
                #     inp_est_obj_axis_red_cam = torch.sum(inp_est_obj_axis_red_wrd[..., None, :]*w2c, -1)
                #     est_mask, est_distance_map = render_distance_map_from_axis(
                #                                     H = self.ddf_H, 
                #                                     obj_pos_wrd = inp_est_obj_pos_wrd, 
                #                                     axis_green = inp_est_obj_axis_green_cam, 
                #                                     axis_red = inp_est_obj_axis_red_cam, 
                #                                     obj_scale = inp_est_obj_scale[:, 0], 
                #                                     input_lat_vec = inp_est_shape_code, 
                #                                     cam_pos_wrd = cam_pos_wrd, 
                #                                     rays_d_cam = rays_d_cam, 
                #                                     w2c = w2c.detach(), 
                #                                     ddf = self.ddf, 
                #                                     with_invdistance_map = False)
                #     _, est_normalized_depth_map, _ = get_normalized_depth_map(
                #                                         est_mask, est_distance_map, rays_d_cam, avg_depth_map, 
                #                                         )
                #     error = torch.abs(est_normalized_depth_map - normalized_depth_map)
                #     error = error.reshape(batch_size, opt_frame_num, self.ddf_H, self.ddf_H).mean(dim=-1).mean(dim=-1)
                #     error = error.mean(dim=-1)

                #     # Make update mask.
                #     un_update_mask = (pre_error - error) < 0.
                #     decade_all_error = not un_update_mask.any()
                #     over_lamda_step = half_lambda_idx + 1 == self.half_lambda_max

                #     # 更新により、エラーが全てのバッチで小さくなった or ラムダステップの最大まで行った
                #     # -> 次の最適化ステップかフレームへ
                #     if decade_all_error or over_lamda_step:
                #         # Update values.
                #         est_obj_pos_wrd[un_update_mask] = pre_obj_pos_wrd[un_update_mask]
                #         est_obj_scale[un_update_mask] = pre_obj_scale[un_update_mask]
                #         est_obj_axis_green_wrd[un_update_mask] = pre_obj_axis_green_wrd[un_update_mask]
                #         est_obj_axis_red_wrd[un_update_mask] = pre_obj_axis_red_wrd[un_update_mask]
                #         est_shape_code[un_update_mask] = pre_shape_code[un_update_mask]
                #         break # ラムダステップ終了。

                #     # 更新により、エラーが全てのバッチで小さくななかった
                #     # -> ならなかったUpdateを半減させて再計算
                #     # -> 具体的にはun_update_maskを変更
                #     else:
                #         lamda_i = 1 / 2**(half_lambda_idx+1)
                #         est_obj_pos_wrd[un_update_mask] = pre_obj_pos_wrd[un_update_mask] + lamda_i * diff_pos_wrd[un_update_mask]
                #         est_obj_scale[un_update_mask] = pre_obj_scale[un_update_mask] * (1. + lamda_i * (diff_scale[un_update_mask] - 1.))
                #         est_obj_axis_green_wrd[un_update_mask] = F.normalize(pre_obj_axis_green_wrd[un_update_mask] + lamda_i * diff_obj_axis_green_wrd[un_update_mask], dim=-1)
                #         est_obj_axis_red_wrd[un_update_mask] = F.normalize(pre_obj_axis_red_wrd[un_update_mask] + lamda_i * diff_obj_axis_red_wrd[un_update_mask], dim=-1)
                #         est_shape_code[un_update_mask] = pre_shape_code[un_update_mask] + lamda_i * diff_shape_code[un_update_mask]
